{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Anjana Tiha\\Drive D\\Programming\\data\\house-prices-advanced-regression-techniques\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\Anjana Tiha\\Drive D\\Programming\\data\\house-prices-advanced-regression-techniques\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train+test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1461.000000</td>\n",
       "      <td>113.794521</td>\n",
       "      <td>140.099917</td>\n",
       "      <td>21033.656164</td>\n",
       "      <td>12.198630</td>\n",
       "      <td>11.150685</td>\n",
       "      <td>3942.535616</td>\n",
       "      <td>3969.731507</td>\n",
       "      <td>207.370523</td>\n",
       "      <td>887.279452</td>\n",
       "      <td>...</td>\n",
       "      <td>945.960274</td>\n",
       "      <td>188.489041</td>\n",
       "      <td>93.320548</td>\n",
       "      <td>43.908219</td>\n",
       "      <td>6.819178</td>\n",
       "      <td>30.121918</td>\n",
       "      <td>5.517808</td>\n",
       "      <td>86.978082</td>\n",
       "      <td>12.643836</td>\n",
       "      <td>4015.631507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>843.220019</td>\n",
       "      <td>84.601142</td>\n",
       "      <td>48.569504</td>\n",
       "      <td>19962.529865</td>\n",
       "      <td>2.765993</td>\n",
       "      <td>2.225599</td>\n",
       "      <td>60.405808</td>\n",
       "      <td>41.290814</td>\n",
       "      <td>362.132413</td>\n",
       "      <td>912.196182</td>\n",
       "      <td>...</td>\n",
       "      <td>427.609683</td>\n",
       "      <td>250.677589</td>\n",
       "      <td>132.512055</td>\n",
       "      <td>122.238297</td>\n",
       "      <td>58.634661</td>\n",
       "      <td>111.514831</td>\n",
       "      <td>80.354614</td>\n",
       "      <td>992.246049</td>\n",
       "      <td>5.407252</td>\n",
       "      <td>2.656190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3744.000000</td>\n",
       "      <td>3900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>731.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>15107.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3908.000000</td>\n",
       "      <td>3934.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>669.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1461.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>18957.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3946.000000</td>\n",
       "      <td>3988.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2190.500000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>23203.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4008.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>1424.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2920.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>430490.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4020.000000</td>\n",
       "      <td>4020.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>11288.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2836.000000</td>\n",
       "      <td>1714.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>1104.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>1476.000000</td>\n",
       "      <td>31000.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4020.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean   1461.000000   113.794521   140.099917   21033.656164    12.198630   \n",
       "std     843.220019    84.601142    48.569504   19962.529865     2.765993   \n",
       "min       2.000000    40.000000    42.000000    2600.000000     2.000000   \n",
       "25%     731.500000    40.000000   118.000000   15107.000000    10.000000   \n",
       "50%    1461.000000   100.000000   138.000000   18957.000000    12.000000   \n",
       "75%    2190.500000   140.000000   160.000000   23203.000000    14.000000   \n",
       "max    2920.000000   380.000000   626.000000  430490.000000    20.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea    BsmtFinSF1  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000   1460.000000   \n",
       "mean     11.150685  3942.535616   3969.731507   207.370523    887.279452   \n",
       "std       2.225599    60.405808     41.290814   362.132413    912.196182   \n",
       "min       2.000000  3744.000000   3900.000000     0.000000      0.000000   \n",
       "25%      10.000000  3908.000000   3934.000000     0.000000      0.000000   \n",
       "50%      10.000000  3946.000000   3988.000000     0.000000    767.000000   \n",
       "75%      12.000000  4000.000000   4008.000000   332.000000   1424.500000   \n",
       "max      18.000000  4020.000000   4020.000000  3200.000000  11288.000000   \n",
       "\n",
       "          ...        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch  \\\n",
       "count     ...       1460.000000  1460.000000  1460.000000    1460.000000   \n",
       "mean      ...        945.960274   188.489041    93.320548      43.908219   \n",
       "std       ...        427.609683   250.677589   132.512055     122.238297   \n",
       "min       ...          0.000000     0.000000     0.000000       0.000000   \n",
       "25%       ...        669.000000     0.000000     0.000000       0.000000   \n",
       "50%       ...        960.000000     0.000000    50.000000       0.000000   \n",
       "75%       ...       1152.000000   336.000000   136.000000       0.000000   \n",
       "max       ...       2836.000000  1714.000000  1094.000000    1104.000000   \n",
       "\n",
       "         3SsnPorch  ScreenPorch     PoolArea       MiscVal       MoSold  \\\n",
       "count  1460.000000  1460.000000  1460.000000   1460.000000  1460.000000   \n",
       "mean      6.819178    30.121918     5.517808     86.978082    12.643836   \n",
       "std      58.634661   111.514831    80.354614    992.246049     5.407252   \n",
       "min       0.000000     0.000000     0.000000      0.000000     2.000000   \n",
       "25%       0.000000     0.000000     0.000000      0.000000    10.000000   \n",
       "50%       0.000000     0.000000     0.000000      0.000000    12.000000   \n",
       "75%       0.000000     0.000000     0.000000      0.000000    16.000000   \n",
       "max    1016.000000   960.000000  1476.000000  31000.000000    24.000000   \n",
       "\n",
       "            YrSold  \n",
       "count  1460.000000  \n",
       "mean   4015.631507  \n",
       "std       2.656190  \n",
       "min    4012.000000  \n",
       "25%    4014.000000  \n",
       "50%    4016.000000  \n",
       "75%    4018.000000  \n",
       "max    4020.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = 'SalePrice'\n",
    "\n",
    "target = data[target_col]\n",
    "\n",
    "data.drop(columns=target_col, inplace=True)\n",
    "\n",
    "features = data\n",
    "\n",
    "rating_cols = ['ExterQual' 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "rating_score = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0}\n",
    "rating_cols2 = {'BsmtFinType1', 'BsmtFinType2'}\n",
    "rating_score2 = {'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1, 'NA':0}\n",
    "\n",
    "ignore_cols = ['BsmtExposure']\n",
    "features.drop(columns=ignore_cols, inplace=True)\n",
    "\n",
    "features.describe()\n",
    "# target.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
      "       'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
      "       'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
      "       'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars',\n",
      "       'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold'],\n",
      "      dtype='object')\n",
      "Index(['LotFrontage', 'MasVnrArea', 'GarageYrBlt'], dtype='object')\n",
      "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n",
      "       'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
      "       'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType',\n",
      "       'SaleCondition'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# print(data.isnull().sum(axis=1))   \n",
    "\n",
    "features.replace(-np.Inf, np.nan)\n",
    "features.replace(np.Inf, np.nan)\n",
    "\n",
    "\n",
    "dtype_grp = features.columns.to_series().groupby(data.dtypes).groups\n",
    "\n",
    "for dtype in dtype_grp:\n",
    "    print(dtype_grp[dtype])\n",
    "\n",
    "    \n",
    "for dtype in dtype_grp:\n",
    "    if dtype=='int64' :\n",
    "        for col in dtype_grp[dtype]:\n",
    "            features[col] = features[col].fillna(0.0)\n",
    "            features[col]=preprocessing.normalize([features[col]], norm='l2').flatten()\n",
    "            features[col] = features[col].astype('float64')\n",
    "    elif dtype=='float64' :\n",
    "        for col in dtype_grp[dtype]:\n",
    "            features[col] = features[col].fillna(0.0)\n",
    "            features[col]=preprocessing.normalize([features[col]], norm='l2').flatten()\n",
    "            features[col] = features[col].astype('float64')\n",
    "    elif dtype=='object' :\n",
    "        for col in dtype_grp[dtype]:\n",
    "            if col in rating_cols:\n",
    "                features[col].replace(rating_score, regex=True, inplace=True)\n",
    "                features[col] = features[col].fillna(0.0)\n",
    "                features[col] = features[col].astype('float64')\n",
    "            elif col in rating_cols2:\n",
    "                features[col].replace(rating_score2, regex=True, inplace=True)\n",
    "                features[col] = features[col].fillna(0.0)\n",
    "                features[col] = features[col].astype('float64')\n",
    "            else:\n",
    "                try:\n",
    "                    le = preprocessing.LabelEncoder()\n",
    "                    enc = preprocessing.OneHotEncoder()\n",
    "                    le.fit(features[col].astype(str))\n",
    "                    label_enc_feature_val = le.transform(features[col].astype(str))\n",
    "                    features[col] = label_enc_feature_val.astype('float64')\n",
    "\n",
    "#                     enc.fit([label_enc_feature_val])  \n",
    "#                     hot_enc_feature_val = enc.transform([label_enc_feature_val])\n",
    "\n",
    "#                     print(hot_enc_feature_val)\n",
    "\n",
    "#                     features.join(hot_enc_feature_val)\n",
    "#                     features.drop(columns=col)\n",
    "                except ValueError:\n",
    "                    print(col)\n",
    "                    print(\"Oops!  That was no valid number.  Try again...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.values\n",
    "Y = target\n",
    "# print(features.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score\n",
    "    \n",
    "def model_evaluation(X, Y, splitter, model, report, details):\n",
    "    explained_variance_score_val = 0\n",
    "    mean_absolute_error_val = 0\n",
    "    mean_squared_error_val = 0\n",
    "    mean_squared_log_error_val = 0\n",
    "    median_absolute_error_val = 0\n",
    "    r2_score_val = 0\n",
    "    i=0\n",
    "    if report:\n",
    "        print(\"*\"*50, \" START \", \"*\"*50)\n",
    "#         print(\"Spliter Description:\")\n",
    "#         print(splitter)\n",
    "#         print(\"-\"*100, \"\\n\")\n",
    "        print(\"Model Description:\")\n",
    "        print(model)\n",
    "        print(\"-\"*100,\"\\n\")\n",
    "    \n",
    "    for train_index, test_index in splitter.split(X, Y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        # model fitting\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # prediction\n",
    "        predict = model.predict(X_test)\n",
    "\n",
    "        # evaluation scores\n",
    "        explained_variance_score_temp = explained_variance_score(y_test, predict)\n",
    "        mean_absolute_error_temp = mean_absolute_error(y_test, predict)\n",
    "        mean_squared_error_temp = mean_squared_error(y_test, predict)\n",
    "        mean_squared_log_error_temp = mean_squared_log_error(y_test, predict)\n",
    "        median_absolute_error_temp = median_absolute_error(y_test, predict)\n",
    "        r2_score_temp = r2_score(y_test, predict)\n",
    "        \n",
    "        explained_variance_score_val = explained_variance_score_val + explained_variance_score_temp\n",
    "        mean_absolute_error_val = mean_absolute_error_val + mean_absolute_error_temp\n",
    "        mean_squared_error_val = mean_squared_error_val + mean_squared_error_temp\n",
    "        mean_squared_log_error_val = mean_squared_log_error_val + mean_squared_log_error_temp\n",
    "        median_absolute_error_val = median_absolute_error_val + median_absolute_error_temp\n",
    "        r2_score_val = r2_score_val + r2_score_temp\n",
    "        \n",
    "        if details:\n",
    "            print(\"*\"*25,  \" ITERATION - \", i+1, \"*\"*25)\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            print(\"explained_variance_score_temp: \", explained_variance_score_temp)\n",
    "            print(\"mean_absolute_error_temp: \", mean_absolute_error_temp)\n",
    "            print(\"mean_squared_error_temp: \", mean_squared_error_temp)\n",
    "            print(\"mean_squared_log_error_temp: \", mean_squared_log_error_temp)\n",
    "            print(\"median_absolute_error_temp: \", median_absolute_error_temp)\n",
    "            print(\"r2_score_temp: \", r2_score_temp)\n",
    "            \n",
    "#             print(\"-\"*35)\n",
    "#             print(metrics.classification_report(y_test, predict))\n",
    "#             print(\"-\"*35)\n",
    "#             print(\"confusion Matrix:\\n\\n\", metrics.confusion_matrix(y_test, predict))\n",
    "#             print(\"-\"*35)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    split_num = splitter.get_n_splits()\n",
    "    \n",
    "    explained_variance_score_val = explained_variance_score_val/split_num\n",
    "    mean_absolute_error_val = mean_absolute_error_val/split_num\n",
    "    mean_squared_error_val = mean_squared_error_val/split_num\n",
    "    mean_squared_log_error_val = mean_squared_log_error_val/split_num\n",
    "    median_absolute_error_val = median_absolute_error_val/split_num\n",
    "    r2_score_val = r2_score_val/split_num\n",
    "    \n",
    "    if report:\n",
    "        print(\"*\"*50, \" Average For\", i+1, \" Folds\", \"*\"*50)\n",
    "        print(\"\\n\")\n",
    "        print('%50s%s' % (\"Average explained_variance_score: \", explained_variance_score_val))\n",
    "        print('%50s%s' % (\"Average mean_absolute_error: \", mean_absolute_error_val))\n",
    "        print('%50s%s' % (\"Average mean_squared_error: \", mean_squared_error_val))\n",
    "        print('%50s%s' % (\"Average mean_squared_log_error: \", mean_squared_log_error_val))\n",
    "        print('%50s%s' % (\"Average median_absolute_error: \", median_absolute_error_val))\n",
    "        print('%50s%s' % (\"Average r2_score: \", r2_score_val))\n",
    "        print(\"\\n\")\n",
    "        print(\"*\"*100)\n",
    "#         print(\"*\"*50, \" END \", \"*\"*50)\n",
    "    \n",
    "    return explained_variance_score_val, mean_absolute_error_val, mean_squared_error_val, mean_squared_log_error_val, median_absolute_error_val, r2_score_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anjana Tiha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class RandomizedLogisticRegression is deprecated; The class RandomizedLogisticRegression is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliter Description:\n",
      "KFold(n_splits=5, random_state=None, shuffle=True)\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "         n_estimators=50, random_state=None)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.8265867530935708\n",
      "                     Average mean_absolute_error: 47180.4798457463\n",
      "                      Average mean_squared_error: 4578030696.787595\n",
      "                  Average mean_squared_log_error: 0.03874169580550478\n",
      "                   Average median_absolute_error: 34447.30688665347\n",
      "                                Average r2_score: 0.8171945368643984\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "ARDRegression(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, threshold_lambda=10000.0, tol=0.001, verbose=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.6680124367899338\n",
      "                     Average mean_absolute_error: 61673.72469857882\n",
      "                      Average mean_squared_error: 8333720716.068225\n",
      "                  Average mean_squared_log_error: 0.05940353910202721\n",
      "                   Average median_absolute_error: 44662.16123036997\n",
      "                                Average r2_score: 0.6663771538699521\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "BaggingRegressor(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.8302387487690227\n",
      "                     Average mean_absolute_error: 38430.259589041096\n",
      "                      Average mean_squared_error: 4148704789.7876444\n",
      "                  Average mean_squared_log_error: 0.023783252146134755\n",
      "                   Average median_absolute_error: 23394.760000000002\n",
      "                                Average r2_score: 0.8280399828999025\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.719584187202057\n",
      "                     Average mean_absolute_error: 53082.46164383561\n",
      "                      Average mean_squared_error: 6978129987.986302\n",
      "                  Average mean_squared_log_error: 0.04160453519619939\n",
      "                   Average median_absolute_error: 33636.2\n",
      "                                Average r2_score: 0.7188479868266693\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.8481810143298375\n",
      "                     Average mean_absolute_error: 37080.25178082192\n",
      "                      Average mean_squared_error: 3884113692.177644\n",
      "                  Average mean_squared_log_error: 0.022137110945379228\n",
      "                   Average median_absolute_error: 22539.659999999996\n",
      "                                Average r2_score: 0.847486608333815\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "          min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.7149035056715026\n",
      "                     Average mean_absolute_error: 55629.01369863014\n",
      "                      Average mean_squared_error: 7328789563.254794\n",
      "                  Average mean_squared_log_error: 0.04870888236018937\n",
      "                   Average median_absolute_error: 36661.0\n",
      "                                Average r2_score: 0.7124061344896816\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=False,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=None)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: -0.10592933922234363\n",
      "                     Average mean_absolute_error: 325866.54343766597\n",
      "                      Average mean_squared_error: 132991851183.85538\n",
      "                  Average mean_squared_log_error: 81.34120705498682\n",
      "                   Average median_absolute_error: 295888.12226140744\n",
      "                                Average r2_score: -4.329271329952957\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.8795754050198991\n",
      "                     Average mean_absolute_error: 32935.86127838013\n",
      "                      Average mean_squared_error: 3083002267.1558437\n",
      "                  Average mean_squared_log_error: 0.01825638168594178\n",
      "                   Average median_absolute_error: 21822.646845697254\n",
      "                                Average r2_score: 0.8788637082797985\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
      "        tol=1e-05, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.6845126543816321\n",
      "                     Average mean_absolute_error: 58381.55020407777\n",
      "                      Average mean_squared_error: 8089273229.435293\n",
      "                  Average mean_squared_log_error: 0.052090723706342434\n",
      "                   Average median_absolute_error: 40886.35536124677\n",
      "                                Average r2_score: 0.6800917469201357\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "      kernel_params=None)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.7105678669501746\n",
      "                     Average mean_absolute_error: 54675.8478610188\n",
      "                      Average mean_squared_error: 7341120367.435689\n",
      "                  Average mean_squared_log_error: 0.04979446407239009\n",
      "                   Average median_absolute_error: 38370.45041334033\n",
      "                                Average r2_score: 0.7096465633346926\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "          weights='uniform')\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "**************************************************  Average For 6  Folds **************************************************\n",
      "\n",
      "\n",
      "                Average explained_variance_score: 0.6534612319323696\n",
      "                     Average mean_absolute_error: 60328.073150684926\n",
      "                      Average mean_squared_error: 8971780033.977314\n",
      "                  Average mean_squared_log_error: 0.04946039654135251\n",
      "                   Average median_absolute_error: 39833.32\n",
      "                                Average r2_score: 0.6525128788329797\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "**************************************************  START  **************************************************\n",
      "Model Description:\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anjana Tiha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py:314: RuntimeWarning: invalid value encountered in log\n",
      "  return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fb8770ded223>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mevaluation_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mexplained_variance_score_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_squared_error_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_squared_log_error_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmedian_absolute_error_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_score_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregressors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mevaluation_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexplained_variance_score_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mevaluation_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_absolute_error_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-be7ae008d06d>\u001b[0m in \u001b[0;36mmodel_evaluation\u001b[1;34m(X, Y, splitter, model, report, details)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mmean_absolute_error_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mmean_squared_error_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mmean_squared_log_error_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_log_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mmedian_absolute_error_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmedian_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mr2_score_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_log_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),\n\u001b[1;32m--> 315\u001b[1;33m                               sample_weight, multioutput)\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \"\"\"\n\u001b[0;32m    237\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 238\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    239\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[0;32m    240\u001b[0m                                weights=sample_weight)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import (AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomTreesEmbedding, RandomForestRegressor, VotingClassifier)\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ARDRegression, LinearRegression, LogisticRegression, LogisticRegressionCV, logistic_regression_path, HuberRegressor, PassiveAggressiveRegressor, RandomizedLogisticRegression, RANSACRegressor, SGDRegressor, TheilSenRegressor\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB \n",
    "from sklearn.neighbors import KDTree, KNeighborsRegressor, NearestNeighbors, RadiusNeighborsRegressor\n",
    "from sklearn.neural_network import BernoulliRBM, MLPRegressor\n",
    "from sklearn.svm import LinearSVR, NuSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state=None, shuffle =True)\n",
    "\n",
    "\n",
    "regressors = {\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(),\n",
    "    \"ARDRegression\": ARDRegression(),\n",
    "    \"BaggingRegressor\": BaggingRegressor(),\n",
    "#     \"BernoulliRBM\": BernoulliRBM(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(),\n",
    "    \"ExtraTreeRegressor\": ExtraTreeRegressor(),\n",
    "#     \"GaussianMixture\": GaussianMixture(),\n",
    "#     \"GaussianNB\": GaussianNB(),\n",
    "    \"GaussianProcessRegressor\": GaussianProcessRegressor(),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(),\n",
    "    \"HuberRegressor\": HuberRegressor(),\n",
    "#     \"IsotonicRegression\": IsotonicRegression(),\n",
    "    \"KernelRidge\": KernelRidge(),\n",
    "#     \"KDTree\": KDTree(),\n",
    "    \"KNeighborsRegressor\": KNeighborsRegressor(),\n",
    "    \"LinearRegression\": LinearRegression(), \n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"LogisticRegressionCV\": LogisticRegressionCV(),\n",
    "#     \"logistic_regression_path\": logistic_regression_path(),\n",
    "    \"LinearSVR\": LinearSVR(),\n",
    "    \"MLPRegressor\": MLPRegressor(),\n",
    "#     \"MultinomialNB\": MultinomialNB(),\n",
    "    \"NuSVR\": NuSVR(),\n",
    "    \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(),\n",
    "#     \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"RadiusNeighborsRegressor\": RadiusNeighborsRegressor(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "    \"RandomizedLogisticRegression\": RandomizedLogisticRegression(),\n",
    "    \"RANSACRegressor\": RANSACRegressor(),\n",
    "    \"SGDRegressor\": SGDRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"TheilSenRegressor\": TheilSenRegressor(),\n",
    "}\n",
    "    \n",
    "    \n",
    "splitter = kf \n",
    "report = 1\n",
    "details = 1\n",
    "\n",
    "\n",
    "evaluation = {}\n",
    "\n",
    "print(\"Spliter Description:\")\n",
    "print(splitter)\n",
    "        \n",
    "        \n",
    "for name in regressors:\n",
    "    evaluation_temp = []\n",
    "    \n",
    "    explained_variance_score_val, mean_absolute_error_val, mean_squared_error_val, mean_squared_log_error_val, median_absolute_error_val, r2_score_val = model_evaluation(X, Y, splitter, regressors[name], report, details=None)\n",
    "    evaluation_temp.append(explained_variance_score_val)\n",
    "    evaluation_temp.append(mean_absolute_error_val)\n",
    "    evaluation_temp.append(mean_squared_error_val)\n",
    "    evaluation_temp.append(mean_squared_log_error_val)\n",
    "    evaluation_temp.append(median_absolute_error_val)\n",
    "    evaluation_temp.append(r2_score_val)\n",
    "    evaluation[name] = evaluation_temp\n",
    "    \n",
    "\n",
    "rows_list = []\n",
    "for name in evaluation:\n",
    "    rows_list.append([name]+evaluation[name])\n",
    "                           \n",
    "evaluation_pd = pd.DataFrame(rows_list, columns=['explained_variance_score',  'mean_absolute_error', 'mean_squared_error', 'mean_squared_log_error', 'median_absolute_error', 'r2_score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "figure(num=None, figsize=(14, 6), dpi=250)\n",
    "\n",
    "labels= ['accuracy', 'precision', 'recall', 'f1']\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for n in range(0,4):\n",
    "    plt.plot([name for name in evaluation],[evaluation[name][n] for name in evaluation], label = labels[n])\n",
    "\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=True, fancybox=True)\n",
    "plt.xticks(rotation=45)\n",
    "# leg.get_frame().set_alpha(0.5)\n",
    "plt.legend()\n",
    "ax.tick_params(labelsize='large', width=5)\n",
    "ax.grid(True, linestyle='-.')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xlabel('x label')\n",
    "plt.ylabel('y label')\n",
    "\n",
    "plt.title(\"TITLE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
