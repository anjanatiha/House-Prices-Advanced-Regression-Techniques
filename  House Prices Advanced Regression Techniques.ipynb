{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Anjana Tiha\\OneDrive - The University of Memphis\\Programming\\data\\house-prices-advanced-regression-techniques\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\Anjana Tiha\\OneDrive - The University of Memphis\\Programming\\data\\house-prices-advanced-regression-techniques\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train+test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_cols = ['Pclass','Sex','Age','SibSp', 'Parch','Fare','Cabin','Embarked']\n",
    "\n",
    "target_col = 'SalePrice'\n",
    "\n",
    "target = data[target_col]\n",
    "\n",
    "data.drop(columns=target_col)\n",
    "\n",
    "features = data\n",
    "\n",
    "features.describe()\n",
    "target.describe()\n",
    "\n",
    "\n",
    "rating_cols = ['ExterQual' 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "rating_score = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0}\n",
    "rating_cols2 = {'BsmtFinType1', 'BsmtFinType2'}\n",
    "rating_score2 = {'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1, 'NA':0}\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------\n",
      "\n",
      "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
      "       'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
      "       'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
      "       'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars',\n",
      "       'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice'],\n",
      "      dtype='object')\n",
      "Index(['LotFrontage', 'MasVnrArea', 'GarageYrBlt'], dtype='object')\n",
      "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
      "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
      "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
      "       'SaleType', 'SaleCondition'],\n",
      "      dtype='object')\n",
      "  (0, 1459)\t1.0\n",
      "  (0, 1458)\t1.0\n",
      "  (0, 1457)\t1.0\n",
      "  (0, 1456)\t1.0\n",
      "  (0, 1455)\t1.0\n",
      "  (0, 1454)\t1.0\n",
      "  (0, 1453)\t1.0\n",
      "  (0, 1452)\t1.0\n",
      "  (0, 1451)\t1.0\n",
      "  (0, 1450)\t1.0\n",
      "  (0, 1449)\t1.0\n",
      "  (0, 1448)\t1.0\n",
      "  (0, 1447)\t1.0\n",
      "  (0, 1446)\t1.0\n",
      "  (0, 1445)\t1.0\n",
      "  (0, 1444)\t1.0\n",
      "  (0, 1443)\t1.0\n",
      "  (0, 1442)\t1.0\n",
      "  (0, 1441)\t1.0\n",
      "  (0, 1440)\t1.0\n",
      "  (0, 1439)\t1.0\n",
      "  (0, 1438)\t1.0\n",
      "  (0, 1437)\t1.0\n",
      "  (0, 1436)\t1.0\n",
      "  (0, 1435)\t1.0\n",
      "  :\t:\n",
      "  (0, 24)\t1.0\n",
      "  (0, 23)\t1.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 20)\t1.0\n",
      "  (0, 19)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 16)\t1.0\n",
      "  (0, 15)\t1.0\n",
      "  (0, 14)\t1.0\n",
      "  (0, 13)\t1.0\n",
      "  (0, 12)\t1.0\n",
      "  (0, 11)\t1.0\n",
      "  (0, 10)\t1.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 0)\t1.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "index not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-a6569f5622e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhot_enc_feature_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhot_enc_feature_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   6334\u001b[0m         \u001b[1;31m# For SparseDataFrame's benefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6335\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[1;32m-> 6336\u001b[1;33m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[0;32m   6337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6338\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   6357\u001b[0m             \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6359\u001b[1;33m             \u001b[0mcan_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6361\u001b[0m             \u001b[1;31m# join indexes only using concat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   6357\u001b[0m             \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6359\u001b[1;33m             \u001b[0mcan_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6361\u001b[0m             \u001b[1;31m# join indexes only using concat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: index not found"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# print(data.info())\n",
    "print(\"\\n----------------------\\n\")\n",
    "# print(data.isnull().sum(axis=1))   \n",
    "\n",
    "features.replace(-np.Inf, np.nan)\n",
    "features.replace(np.Inf, np.nan)\n",
    "\n",
    "features = features.fillna(0)\n",
    "\n",
    "dtype_grp = features.columns.to_series().groupby(data.dtypes).groups\n",
    "\n",
    "for dtype in dtype_grp:\n",
    "    print(dtype_grp[dtype])\n",
    "\n",
    "for dtype in dtype_grp:\n",
    "    if dtype=='int64' :\n",
    "        for col in dtype_grp[dtype]:\n",
    "            features[col]=preprocessing.normalize([features[col]], norm='l2').flatten()\n",
    "    elif dtype=='float64' :\n",
    "        for col in dtype_grp[dtype]:\n",
    "            features[col]=preprocessing.normalize([features[col]], norm='l2').flatten()\n",
    "    elif dtype=='object' :\n",
    "        for col in dtype_grp[dtype]:\n",
    "            if col in rating_cols:\n",
    "                features[col].replace(rating_score, regex=True, inplace=True)\n",
    "            elif col in rating_cols2:\n",
    "                features[col].replace(rating_score2, regex=True, inplace=True)\n",
    "            else:\n",
    "                le = preprocessing.LabelEncoder()\n",
    "                enc = preprocessing.OneHotEncoder()\n",
    "                \n",
    "                le.fit(features[col])\n",
    "                label_enc_feature_val = le.transform(features[col])\n",
    "                \n",
    "                enc.fit([label_enc_feature_val])  \n",
    "                hot_enc_feature_val = enc.transform([label_enc_feature_val])\n",
    "                \n",
    "                print(hot_enc_feature_val)\n",
    "                \n",
    "                features.join(hot_enc_feature_val)\n",
    "                features.drop(columns=col)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.fillna(0)\n",
    "features['Age']=preprocessing.normalize([features['Age']], norm='l2').flatten()\n",
    "features['Fare'] = preprocessing.normalize([features['Fare']], norm='l2').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(features['Sex'])\n",
    "features['Sex']=le.transform(features['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# enc = OneHotEncoder()\n",
    "# enc.fit(Y)  \n",
    "# Y=enc.transform(Y).toarray()\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.values\n",
    "Y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "    \n",
    "def model_evaluation(X, Y, splitter, model, report, details):\n",
    "    accuracy = 0\n",
    "    f1 = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    i=0\n",
    "    if report:\n",
    "        print(\"*\"*50, \" START \", \"*\"*50)\n",
    "        print(\"Spliter Description:\")\n",
    "        print(splitter)\n",
    "        print(\"-\"*100, \"\\n\")\n",
    "        print(\"Model Description:\")\n",
    "        print(model)\n",
    "        print(\"-\"*100,\"\\n\")\n",
    "    \n",
    "    for train_index, test_index in splitter.split(X, Y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        # model fitting\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # prediction\n",
    "        predict = model.predict(X_test)\n",
    "\n",
    "        # evaluation scores\n",
    "        accuracy_temp = metrics.accuracy_score(y_test, predict)\n",
    "        precision_temp = metrics.precision_score(y_test, predict, average=\"micro\")\n",
    "        recall_temp = metrics.recall_score(y_test, predict, average=\"micro\")\n",
    "        f1_temp = metrics.f1_score(y_test, predict, average=\"micro\")\n",
    "        hamming_loss = metrics.hamming_loss(y_test, predict)\n",
    "        \n",
    "#         precision, recall, thresholds = metrics.precision_recall_curve(y_test, predict)\n",
    "#         average_precision_score = metrics.average_precision_score(y_test, predict, average=\"micro\")\n",
    "#         fbeta_score = metrics.fbeta_score(y_test, predict)\n",
    "#         roc_auc_score = metrics.roc_auc_score(y_test, predict, average=\"micro\")\n",
    "        \n",
    "    \n",
    "        accuracy = accuracy + accuracy_temp\n",
    "        precision = precision + precision_temp\n",
    "        recall = recall+ recall_temp\n",
    "        f1= f1 + f1_temp\n",
    "        \n",
    "        if details:\n",
    "            print(\"*\"*25,  \" ITERATION - \", i+1, \"*\"*25)\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            print(\"Accuracy Score: \", accuracy_temp)\n",
    "            print(\"Precision Score: \", precision_temp)\n",
    "            print(\"Recall Score: \", recall_temp)\n",
    "            print(\"F1 Score: \", f1_temp)\n",
    "            print(\"Hamming Loss: \", hamming_loss)\n",
    "            print(\"-\"*35)\n",
    "            print(metrics.classification_report(y_test, predict))\n",
    "            print(\"-\"*35)\n",
    "            print(\"confusion Matrix:\\n\\n\", metrics.confusion_matrix(y_test, predict))\n",
    "            print(\"-\"*35)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        i+=1\n",
    "    split_num = splitter.get_n_splits()\n",
    "    accuracy = accuracy/split_num\n",
    "    precision = precision/split_num\n",
    "    recall = recall/split_num\n",
    "    f1 = f1/split_num\n",
    "    \n",
    "    if report:\n",
    "        print(\"*\"*50, \" Average For\", i+1, \" Folds\", \"*\"*50)\n",
    "        print(\"\\n\")\n",
    "        print(\"Average Accuracy Score: \", accuracy)\n",
    "        print(\"Average pPrecision Score: \", precision)\n",
    "        print(\"Average Recall Score: \", recall)\n",
    "        print(\"Average F1 Score:\", f1)\n",
    "        print(\"\\n\")\n",
    "        print(\"*\"*50, \" END \", \"*\"*50)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import (AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomTreesEmbedding, RandomForestClassifier, VotingClassifier)\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB \n",
    "from sklearn.neighbors import KDTree, KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.neural_network import BernoulliRBM, MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "#     \"BernoulliRBM\": BernoulliRBM(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(),\n",
    "    \"GaussianMixture\": GaussianMixture(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"GaussianProcessClassifier\": GaussianProcessClassifier(),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "#     \"KDTree\": KDTree(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(3),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"LinearSVC\": LinearSVC(),\n",
    "    \"MLPClassifier\": MLPClassifier(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "#     \"NearestNeighbors\": NearestNeighbors(),\n",
    "    \"NuSVC\": NuSVC(),\n",
    "    \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"SVC Linear\": SVC(kernel=\"linear\", C=0.025),\n",
    "    \"SVC\": SVC(),\n",
    "    \"SVC Gamma\": SVC(gamma=2, C=1)\n",
    "#     VotingClassifier: VotingClassifier(),\n",
    "}\n",
    "    \n",
    "    \n",
    "splitter = sss\n",
    "report = None\n",
    "details = 1\n",
    "\n",
    "\n",
    "evaluation = {}\n",
    "\n",
    "for name in classifiers:\n",
    "    evaluation_temp = []\n",
    "    accuracy, precision, recall, f1 = model_evaluation(X, Y, splitter, classifiers[name], report=None, details=None)\n",
    "    evaluation_temp.append(accuracy)\n",
    "    evaluation_temp.append(precision)\n",
    "    evaluation_temp.append(recall)\n",
    "    evaluation_temp.append(f1)\n",
    "    evaluation[name] = evaluation_temp\n",
    "    \n",
    "\n",
    "rows_list = []\n",
    "for name in evaluation:\n",
    "    rows_list.append([name]+evaluation[name])\n",
    "                           \n",
    "evaluation_pd = pd.DataFrame(rows_list, columns=['model', 'accuracy', 'precision', 'recall', 'f1']) \n",
    "evaluation_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "figure(num=None, figsize=(14, 6), dpi=250)\n",
    "\n",
    "labels= ['accuracy', 'precision', 'recall', 'f1']\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for n in range(0,4):\n",
    "    plt.plot([name for name in evaluation],[evaluation[name][n] for name in evaluation], label = labels[n])\n",
    "\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=True, fancybox=True)\n",
    "plt.xticks(rotation=45)\n",
    "# leg.get_frame().set_alpha(0.5)\n",
    "plt.legend()\n",
    "ax.tick_params(labelsize='large', width=5)\n",
    "ax.grid(True, linestyle='-.')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xlabel('x label')\n",
    "plt.ylabel('y label')\n",
    "\n",
    "plt.title(\"TITLE\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
