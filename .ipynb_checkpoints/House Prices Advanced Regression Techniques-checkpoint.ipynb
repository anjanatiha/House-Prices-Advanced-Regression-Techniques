{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*****************************************************************************************************************************************\\n*****************************************************************************************************************************************\\n* Author             : Anjana Tiha\\n* Author Details     : Masters of Science, Computer Science, University of Memphis, Memphis, Tennessee, USA (May 2018)\\n*****************************************************************************************************************************************\\n*****************************************************************************************************************************************\\n* Project Name       : Regression Modeling for Housing Price Prediction based on Numerical and Categorical Features\\n* Description        : 1. Built regression model for predicting housing price using 79 numerical and categorical features. \\n*                      2. Built pipelines for machine learning (regression) model training for reading files, creating training\\n*                         testing dataset, preprocessing (normalization, label encoding of categorical features), extracting \\n*                         features, and training and evaluation in grid search approach for multiple regression models.\\n*                      3. Generated visualization and aggregated report on the performance of various models.\\n* Procedure          : 1. Build pipelines for machine learning model training for reading file, creating training testing \\n*                         dataset, preprocessing (normalization, label encoding of categorical features), extracting features, \\n*                         and training and evaluation in grid search approach for mutiple regression models.\\n*                      2. Preprocessing unit replaced non standard input features with default value and performed normalization,\\n*                         label encoding of categorical features.\\n*                      3. Build feature set using almost all available features.\\n*                      4. Build model training pipeline for regression\\n*                      5. Generate agregated report on performance for various models.\\n*                      6. Visualization for different model performance.\\n* Input              : \\n* Output             : \\n* Start Date         : 09.22.2018\\n* Last Update        : \\n* Tools Requirement  : Anaconda, Python\\n* Comments           : Please use Anaconda editor for visualization and convenience.\\n* Version History    : 1.0.0.0\\n* Current Version    : 1.0.0.0\\n*****************************************************************************************************************************************\\n*****************************************************************************************************************************************\\n\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "*****************************************************************************************************************************************\n",
    "*****************************************************************************************************************************************\n",
    "* Author             : Anjana Tiha\n",
    "* Author Details     : Masters of Science, Computer Science, University of Memphis, Memphis, Tennessee, USA (May 2018)\n",
    "*****************************************************************************************************************************************\n",
    "*****************************************************************************************************************************************\n",
    "* Project Name       : Regression Modeling for Housing Price Prediction based on Numerical and Categorical Features\n",
    "* Description        : 1. Built regression model for predicting housing price using 79 numerical and categorical features. \n",
    "*                      2. Built pipelines for machine learning (regression) model training for reading files, creating training\n",
    "*                         testing dataset, preprocessing (normalization, label encoding of categorical features), extracting \n",
    "*                         features, and training and evaluation in grid search approach for multiple regression models.\n",
    "*                      3. Generated visualization and aggregated report on the performance of various models.\n",
    "* Procedure          : 1. Build pipelines for machine learning model training for reading file, creating training testing \n",
    "*                         dataset, preprocessing (normalization, label encoding of categorical features), extracting features, \n",
    "*                         and training and evaluation in grid search approach for mutiple regression models.\n",
    "*                      2. Preprocessing unit replaced non standard input features with default value and performed normalization,\n",
    "*                         label encoding of categorical features.\n",
    "*                      3. Build feature set using almost all available features.\n",
    "*                      4. Build model training pipeline for regression\n",
    "*                      5. Generate agregated report on performance for various models.\n",
    "*                      6. Visualization for different model performance.\n",
    "* Input              : \n",
    "* Output             : \n",
    "* Start Date         : 09.22.2018\n",
    "* Last Update        : \n",
    "* Tools Requirement  : Anaconda, Python\n",
    "* Comments           : Please use Anaconda editor for visualization and convenience.\n",
    "* Version History    : 1.0.0.0\n",
    "* Current Version    : 1.0.0.0\n",
    "*****************************************************************************************************************************************\n",
    "*****************************************************************************************************************************************\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from string import punctuation\n",
    "import re\n",
    "from tokenize import tokenize\n",
    "import nltk, re, time\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self, train_X_file, train_Y_file, test_X_file, test_Y_file):\n",
    "        if train_X_file:\n",
    "            self.train_X = pd.read_csv(train_X_file)\n",
    "        if train_Y_file:\n",
    "            self.train_Y = pd.read_csv(train_Y_file)\n",
    "        else:\n",
    "            self.train_Y = None\n",
    "        if test_X_file:\n",
    "            self.test_X = pd.read_csv(test_X_file)\n",
    "        if test_Y_file:\n",
    "            self.test_Y = pd.read_csv(test_Y_file)\n",
    "        else:\n",
    "            self.test_Y = None\n",
    "            \n",
    "    def get_content(self):\n",
    "        return self.train_X, self.train_Y, self.test_X, self.test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, train_test, train_XY, test_XY, targets):\n",
    "        self.train_X = train_X\n",
    "        self.test_X = test_X\n",
    "     \n",
    "        self.train_Y = None\n",
    "        self.test_Y = None\n",
    "        \n",
    "        self.feature_cols = None\n",
    "        self.targets = targets\n",
    "        \n",
    "        if train_XY:\n",
    "            self.train_Y = self.train_X[self.targets]\n",
    "            \n",
    "            self.train_X.drop(columns=self.targets, inplace=True)           \n",
    "        else:\n",
    "            self.train_Y = train_Y\n",
    "            \n",
    "            \n",
    "            \n",
    "        if test_XY:\n",
    "            print(targets)\n",
    "            self.test_Y = test_X[self.targets]        \n",
    "            self.test_X.drop(columns=targets, inplace=True)\n",
    "        else:\n",
    "            self.test_Y = test_Y\n",
    "        \n",
    "#         self.train_X.drop(columns='id', inplace=True)\n",
    "#         self.test_X.drop(columns='id', inplace=True)\n",
    "\n",
    "    def set_feature_cols(self, feature_cols):\n",
    "        if self.feature_cols:\n",
    "            self.feature_cols.append(feature_cols)\n",
    "        else: self.feature_cols = feature_cols\n",
    "            \n",
    "    def remove_feature_cols(self, feature_cols):\n",
    "        if self.feature_cols:\n",
    "            self.feature_cols.remove(feature_cols)\n",
    "        else: self.feature_cols = None\n",
    "            \n",
    "    \n",
    "    def fill_columns_selected(self, columns_names, columns_val, inplace=True):\n",
    "        for cols in columns_names:\n",
    "            self.train_X[cols].fillna(columns_val, inplace=inpl)\n",
    "            self.test_X[cols].fillna(columns_val, inplace=inpl)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.train_X, self.train_Y, self.test_X, self.test_Y\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def clean_text(self, text, alpha=True, punc=False, case_active=False, remove_stopwords=True):\n",
    "        if alpha:\n",
    "            text  = re.sub(r\"[^a-z]\", \" \", text)\n",
    "        if case_active==False:\n",
    "            text  = text .lower()\n",
    "        if punc==False:\n",
    "            text  = ''.join([c for c in text if c not in punctuation])\n",
    "        if remove_stopwords:\n",
    "            cached_stopwords = stopwords.words(\"english\")\n",
    "            self.text = ' '.join([word for word in text.split() if word not in cached_stopwords])\n",
    "        text = re.sub(r\" +\", \" \", text)\n",
    "        text = text.strip()\n",
    "        text = text .split()\n",
    "        return text   \n",
    "\n",
    "    \n",
    "    def tokenize(self, text, alpha=True, punc=False, case_active=False, remove_stopwords=True):\n",
    "        if alpha:\n",
    "            text = re.sub(r\"[^a-z]\", \" \", text)\n",
    "        if case_active==False:\n",
    "            text = text.lower()\n",
    "        if punc==False:\n",
    "            text = ''.join([c for c in text if c not in punctuation])\n",
    "        if remove_stopwords:\n",
    "            cached_stopwords = stopwords.words(\"english\")\n",
    "            text = ' '.join([word for word in text.split() if word not in cached_stopwords])\n",
    "        text = re.sub(r\" +\", \" \", text)\n",
    "        text = text.strip()\n",
    "        text = text.split()\n",
    "        return text \n",
    "\n",
    "\n",
    "    def single_char_cnt(self, text, alpha=False, punc=False, remove_stopwords=True):\n",
    "        if alpha:\n",
    "            text = re.sub(r\"[^a-z]\", \" \", text)\n",
    "        if punc==False:\n",
    "            text = ''.join([c for c in text if c not in punctuation])\n",
    "        if remove_stopwords:\n",
    "            cached_stopwords = stopwords.words(\"english\")\n",
    "            text = ' '.join([word for word in text.split() if word not in cached_stopwords])\n",
    "\n",
    "        text = re.sub(r\" +\", \" \", text)\n",
    "        text = text.strip()\n",
    "        text = text.split()\n",
    "\n",
    "        c=0\n",
    "        for tok in text:\n",
    "            if len(tok.strip())==1: c+=1\n",
    "        return  c\n",
    "\n",
    "    \n",
    "    def find_urls(self, text):\n",
    "        return re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', text)\n",
    "\n",
    "\n",
    "    def count_modals(self, text):\n",
    "        modals = ['can', 'could', 'may', 'might', 'must', 'will', 'would', 'should']\n",
    "\n",
    "        toks = text.split(' ')\n",
    "\n",
    "        c=0\n",
    "        for tok in toks:\n",
    "            if tok in modals: c+=1\n",
    "        return c\n",
    "\n",
    "    \n",
    "    def non_alpha_mid(self, text, alpha=False, punc=False, remove_stopwords=True):\n",
    "        text = re.sub(r\" +\", \" \", text)\n",
    "        if punc==False:\n",
    "            text = ''.join([c for c in text if c not in punctuation])\n",
    "        if remove_stopwords:\n",
    "            cached_stopwords = stopwords.words(\"english\")\n",
    "            text = ''.join([word for word in text if word not in cached_stopwords])\n",
    "\n",
    "        text = text.split()\n",
    "\n",
    "        c=0\n",
    "        for tok in text:\n",
    "            m=0\n",
    "            for ch in tok:\n",
    "                if ch.isalpha()==0: m+=1\n",
    "            if (m>1 and len(tok)>1) or (m>=1): c+=1\n",
    "        return c\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TextFeatures:    \n",
    "    def __init__(self, train_X, test_X, columns_text):\n",
    "        self.train_X = train_X\n",
    "        self.test_X = test_X\n",
    "        self.columns_text = columns_text\n",
    "        \n",
    "        self.train_X_features = []\n",
    "        self.test_X_features = []\n",
    "        self.train_X_tfidf = None\n",
    "        self.test_X_tfidf = None\n",
    "        \n",
    "        \n",
    "    def get_features_X(self, X, features):\n",
    "        count = lambda l1, l2: len(list(filter(lambda c: c in l2, l1)))\n",
    "        prep_obj = Preprocess()\n",
    "        \n",
    "        features = []\n",
    "        try:\n",
    "            for col in self.columns_text:\n",
    "                length=X[col].size\n",
    "                \n",
    "                i=0\n",
    "                features_col = []\n",
    "                for line in range(0, length):\n",
    "                    counts = []\n",
    "                \n",
    "                    text = X[col][line]\n",
    "                    \n",
    "                    counts.append(text.count(\"!\"))\n",
    "                    counts.append(text.count(\"?\"))\n",
    "                    counts.append(text.count(\".\"))\n",
    "                    counts.append(count(text,set(string.punctuation)))\n",
    "                    counts.append(len(re.findall('[''\"\"]', text)))\n",
    "                    \n",
    "                    counts.append(prep_obj.single_char_cnt(text, alpha=False, punc=False, remove_stopwords=False))\n",
    "                    \n",
    "                    counts.append(len(prep_obj.find_urls(text)))\n",
    "                    \n",
    "                    counts.append(len(text))\n",
    "                    counts.append(len(text.split()))\n",
    "                    counts.append(sum(1 for c in text if c.isupper()))\n",
    "\n",
    "                    counts.append(prep_obj.count_modals(text))\n",
    "                    \n",
    "                    counts.append(len(re.findall(r'[\\U0001f600-\\U0001f650]', text)))\n",
    "                    counts.append(prep_obj.non_alpha_mid(text, alpha=False, punc=False, remove_stopwords=False))\n",
    "                    \n",
    "                    features_col.append(counts)\n",
    "                    i+=1\n",
    "#                     if i%10000==0: print(i)\n",
    "                \n",
    "    \n",
    "                features_col = np.array(features_col, dtype='int64')\n",
    "                features.append(features_col)\n",
    "        except:\n",
    "            print(\"Error:\", line)\n",
    "                \n",
    "        return features\n",
    "    \n",
    "    \n",
    "    def get_tfidf_features(self, tfidf, column):\n",
    "        self.train_X_tfidf = tfidf.fit_transform(train[column])\n",
    "        self.test_X_tfidf = tfidf.transform(test[column])\n",
    "        \n",
    "        return self.train_X_tfidf, self.test_X_tfidf\n",
    "    \n",
    "    \n",
    "    def get_features(self):\n",
    "        self.train_X_features = self.get_features_X(self.train_X, self.columns_text)\n",
    "        self.test_X_features = self.get_features_X(self.test_X, self.columns_text)\n",
    "        \n",
    "        return self.train_X_features, self.test_X_features \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "class PreprocessNumeric:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def fill_col(self, train_X, train_Y, test_X, test_Y):\n",
    "        if len(train_X)>0:\n",
    "            train_X.replace(-np.Inf, np.nan)\n",
    "            train_X.replace(np.Inf, np.nan)\n",
    "            train_X.replace(np.nan, 0)\n",
    "            train_X = train_X.fillna(0)\n",
    "        if len(train_Y)>0:\n",
    "            train_Y.replace(-np.Inf, np.nan)\n",
    "            train_Y.replace(np.Inf, np.nan)\n",
    "            train_Y.replace(np.nan, 0)\n",
    "            train_Y = train_Y.fillna(0)\n",
    "\n",
    "#         if len(test_X)>0:\n",
    "#             test_X.replace(-np.Inf, np.nan)\n",
    "#             test_X.replace(np.Inf, np.nan)\n",
    "#             test_X.replace(np.nan, 0)\n",
    "#             test_X = test_X.fillna(0)\n",
    "            \n",
    "#         if len(test_Y)>0:\n",
    "#             test_Y.replace(-np.Inf, np.nan)\n",
    "#             test_Y.replace(np.Inf, np.nan)\n",
    "#             test_Y.replace(np.nan, 0)\n",
    "#             test_Y = test_Y.fillna(0)\n",
    "         \n",
    "        return train_X, train_Y, test_X, test_Y\n",
    "        \n",
    "        \n",
    "    def drop_cols(self, train_X, test_X, ignore_cols):\n",
    "        train_X.drop(columns=ignore_cols, inplace=True)\n",
    "        test_X.drop(columns=ignore_cols, inplace=True)\n",
    "        return train_X, test_X\n",
    "    \n",
    "    \n",
    "    def normalize_target(self, train_Y, test_Y):\n",
    "        \n",
    "        normalizer_train_m = {}\n",
    "        normalizer_test_m = {}\n",
    "        \n",
    "        for col in train_Y:\n",
    "            normalizer_train = Normalizer(copy=False)\n",
    "            normalizer_test = Normalizer(copy=False)\n",
    "            \n",
    "            \n",
    "            normalizer_train.fit([train_Y[col]])\n",
    "            train_Y[col] = normalizer_train.transform([train_Y[col]]).flatten().astype('float64') \n",
    "        \n",
    "            if test_Y:\n",
    "                normalizer_test.fit([test_Y[col]])\n",
    "                test_Y[col] = normalizer_test.transform([test_Y[col]]).flatten().astype('float64') \n",
    "                \n",
    "            normalizer_train_m[col] = normalizer_train\n",
    "            normalizer_test_m[col] = normalizer_test\n",
    "\n",
    "        return train_Y, test_Y, normalizer_train_m, normalizer_test_m\n",
    "    \n",
    "    \n",
    "    \n",
    "    def encoding_type(self, features, rating_score):\n",
    "        dtype_grp = features.columns.to_series().groupby(features.dtypes).groups\n",
    "\n",
    "#         for dtype in dtype_grp:\n",
    "#             print(dtype, len(dtype_grp[dtype]))\n",
    "\n",
    "#         i=0\n",
    "        for dtype in dtype_grp:\n",
    "            if dtype=='int64' :\n",
    "                for col in dtype_grp[dtype]:\n",
    "                    features[col] = features[col].fillna(0.0)\n",
    "                    features[col]=preprocessing.normalize([features[col]], norm='l2').flatten()\n",
    "                    features[col] = features[col].astype('float64')\n",
    "#                     i+=1\n",
    "            elif dtype=='float64' :\n",
    "                for col in dtype_grp[dtype]:\n",
    "                    features[col] = features[col].fillna(0.0)\n",
    "                    features[col]=preprocessing.normalize([features[col]], norm='l2').flatten()\n",
    "                    features[col] = features[col].astype('float64')\n",
    "#                     i+=1\n",
    "            elif dtype=='object' :\n",
    "                for col in dtype_grp[dtype]:\n",
    "                    if col in rating_score:\n",
    "                        features[col].replace(rating_score[col], regex=True, inplace=True)\n",
    "                        features[col] = features[col].fillna(0.0)\n",
    "                        features[col] = features[col].astype('float64')\n",
    "#                         i+=1\n",
    "                    else:\n",
    "                        try:\n",
    "                            le = preprocessing.LabelEncoder()\n",
    "                            enc = preprocessing.OneHotEncoder()\n",
    "                            le.fit(features[col].astype(str))\n",
    "                            label_enc_feature_val = le.transform(features[col].astype(str))\n",
    "                            features[col] = label_enc_feature_val.astype('float64')\n",
    "#                             i+=1\n",
    "\n",
    "        #                     enc.fit([label_enc_feature_val])  \n",
    "        #                     hot_enc_feature_val = enc.transform([label_enc_feature_val])\n",
    "\n",
    "        #                     print(hot_enc_feature_val)\n",
    "\n",
    "        #                     features.join(hot_enc_feature_val)\n",
    "        #                     features.drop(columns=col)\n",
    "                        except ValueError:\n",
    "                            print(col)\n",
    "                            print(\"Oops!  That was no valid number.  Try again...\")\n",
    "#         print(\"i--.\", i)\n",
    "                        \n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NumricFeatures:    \n",
    "    def __init__(self, train_X, test_X, columns_text):\n",
    "        self.train_X = train_X\n",
    "        self.test_X = test_X\n",
    "        self.columns_text = columns_text\n",
    "        \n",
    "        self.train_X_features = []\n",
    "        self.test_X_features = []\n",
    "        self.train_X_tfidf = None\n",
    "        self.test_X_tfidf = None\n",
    "    \n",
    "    \n",
    "    def get_features(self):\n",
    "        self.train_X_features = self.get_features_X(self.train_X, self.columns_text)\n",
    "        self.test_X_features = self.get_features_X(self.test_X, self.columns_text)\n",
    "        \n",
    "        return self.train_X_features, self.test_X_features \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Splitter:\n",
    "    def __init__(self, splitter_name, n_splits, test_size, random_state):\n",
    "        self.splitter = None\n",
    "        if splitter_name == 'KFold':\n",
    "            self.splitter = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        elif splitter_name == 'StratifiedShuffleSplit':\n",
    "            self.splitter = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "            \n",
    "    def get_splitter(self):\n",
    "        return self.splitter\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import (AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomTreesEmbedding, RandomForestClassifier, VotingClassifier)\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB \n",
    "from sklearn.neighbors import KDTree, KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.neural_network import BernoulliRBM, MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# regressor\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import (AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomTreesEmbedding, RandomForestRegressor, VotingClassifier)\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ARDRegression, LinearRegression, LogisticRegression, LogisticRegressionCV, logistic_regression_path, HuberRegressor, PassiveAggressiveRegressor, RandomizedLogisticRegression, RANSACRegressor, SGDRegressor, TheilSenRegressor\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB \n",
    "from sklearn.neighbors import KDTree, KNeighborsRegressor, NearestNeighbors, RadiusNeighborsRegressor\n",
    "from sklearn.neural_network import BernoulliRBM, MLPRegressor\n",
    "from sklearn.svm import LinearSVR, NuSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, model_type):\n",
    "        if model_type == 'Classification':\n",
    "            self.models = {\n",
    "                \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "                \"BernoulliNB\": BernoulliNB(),\n",
    "#                 \"BernoulliRBM\": BernoulliRBM(),\n",
    "                \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "                \"ExtraTreesClassifier\": ExtraTreesClassifier(),\n",
    "#                 \"GaussianMixture\": GaussianMixture(),\n",
    "#                 \"GaussianNB\": GaussianNB(),\n",
    "#                 \"GaussianProcessClassifier\": GaussianProcessClassifier(),\n",
    "                \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "#                 \"KDTree\": KDTree(),\n",
    "#                 \"KNeighborsClassifier\": KNeighborsClassifier(3),\n",
    "                \"LogisticRegression\": LogisticRegression(),\n",
    "                \"LinearSVC\": LinearSVC(),\n",
    "                \"MLPClassifier\": MLPClassifier(),\n",
    "                \"MultinomialNB\": MultinomialNB(),\n",
    "#                 \"NearestNeighbors\": NearestNeighbors(),\n",
    "#                 \"NuSVC\": NuSVC(),\n",
    "                \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "                \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "#                 \"SVC Linear\": SVC(kernel=\"linear\", C=0.025),\n",
    "#                 \"SVC radial\": SVC(kernel=\"radial\", C=0.025),\n",
    "#                 \"SVC\": SVC(),\n",
    "#                 \"SVC Gamma\": SVC(gamma=2, C=1)\n",
    "#                 VotingClassifier: VotingClassifier(),\n",
    "            }\n",
    "        elif model_type == 'Regression':\n",
    "            self.models  = {\n",
    "                \"AdaBoostRegressor\": AdaBoostRegressor(),\n",
    "#                 \"ARDRegression\": ARDRegression(),\n",
    "                \"BaggingRegressor\": BaggingRegressor(),\n",
    "#                 \"BernoulliRBM\": BernoulliRBM(),\n",
    "                \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "                \"ExtraTreesRegressor\": ExtraTreesRegressor(),\n",
    "                \"ExtraTreeRegressor\": ExtraTreeRegressor(),\n",
    "#                 \"GaussianMixture\": GaussianMixture(),\n",
    "#                 \"GaussianNB\": GaussianNB(),\n",
    "                \"GaussianProcessRegressor\": GaussianProcessRegressor(),\n",
    "                \"GradientBoostingRegressor\": GradientBoostingRegressor(),\n",
    "                \"HuberRegressor\": HuberRegressor(),\n",
    "#                 \"IsotonicRegression\": IsotonicRegression(),\n",
    "#                 \"KernelRidge\": KernelRidge(),\n",
    "#                 \"KDTree\": KDTree(),\n",
    "#                 \"KNeighborsRegressor\": KNeighborsRegressor(),\n",
    "                \"LinearRegression\": LinearRegression(), \n",
    "#                 \"LogisticRegression\": LogisticRegression(),\n",
    "#                 \"LogisticRegressionCV\": LogisticRegressionCV(),\n",
    "#                 \"logistic_regression_path\": logistic_regression_path(),\n",
    "                \"LinearSVR\": LinearSVR(),\n",
    "                \"MLPRegressor\": MLPRegressor(),\n",
    "#                 \"MultinomialNB\": MultinomialNB(),\n",
    "                \"NuSVR\": NuSVR(),\n",
    "                \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(),\n",
    "#                 \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "#                 \"RadiusNeighborsRegressor\": RadiusNeighborsRegressor(),\n",
    "                \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "#                 \"RandomizedLogisticRegression\": RandomizedLogisticRegression(),\n",
    "#                 \"RANSACRegressor\": RANSACRegressor(),\n",
    "#                 \"SGDRegressor\": SGDRegressor(),\n",
    "                \"SVR\": SVR(),\n",
    "                \"TheilSenRegressor\": TheilSenRegressor(),\n",
    "            }\n",
    "    \n",
    "    def get_models(self):\n",
    "        return self.models\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "class ModelClassification:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, targets, splitter, models, average, report, details):\n",
    "        \n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y\n",
    "        \n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y\n",
    "        \n",
    "        self.targets = targets\n",
    "        \n",
    "        self.splitter = splitter\n",
    "        \n",
    "        self.models = models\n",
    "        \n",
    "        self.average = average\n",
    "        \n",
    "        self.report = report\n",
    "        self.details = details\n",
    "        \n",
    "        self.accuracy = 0\n",
    "        self.f1 = 0\n",
    "        self.precision = 0\n",
    "        self.recall = 0\n",
    "    \n",
    "    \n",
    "    def reset_score(self):\n",
    "        self.accuracy = 0\n",
    "        self.f1 = 0\n",
    "        self.precision = 0\n",
    "        self.recall = 0\n",
    "            \n",
    "    def model_evaluation(self, model, target):\n",
    "        self.reset_score()\n",
    " \n",
    "        if self.report:\n",
    "            print(\"Model Description:\")\n",
    "            print(model)\n",
    "            print(\"-\"*100,\"\\n\")\n",
    "            \n",
    "        train_Y = np.array(self.train_Y[target], dtype='int64')\n",
    "        test_Y = np.array(self.test_Y[target], dtype='int64')\n",
    "        \n",
    "        if self.splitter:\n",
    "            i=0\n",
    "            for train_index, test_index in self.splitter.split(self.train_X, train_Y):\n",
    "                X_train, X_test = self.train_X[train_index], self.train_X[test_index]\n",
    "                y_train, y_test = train_Y[train_index], train_Y[test_index]\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                if len(self.test_X)>0:\n",
    "                    predict = model.predict(self.test_X)\n",
    "                    accuracy_temp = metrics.accuracy_score(test_Y, predict)\n",
    "                    precision_temp = metrics.precision_score(test_Y, predict, average=self.average)\n",
    "                    recall_temp = metrics.recall_score(test_Y, predict, average=self.average)\n",
    "                    f1_temp = metrics.f1_score(test_Y, predict, average=self.average)\n",
    "                    hamming_loss = metrics.hamming_loss(test_Y, predict)\n",
    "                else:\n",
    "                    predict = model.predict(X_test)\n",
    "                    accuracy_temp = metrics.accuracy_score(y_test, predict)\n",
    "                    precision_temp = metrics.precision_score(y_test, predict, average=self.average)\n",
    "                    recall_temp = metrics.recall_score(y_test, predict, average=self.average)\n",
    "                    f1_temp = metrics.f1_score(y_test, predict, average=self.average)\n",
    "                    hamming_loss = metrics.hamming_loss(y_test, predict)\n",
    "\n",
    "                self.accuracy = self.accuracy + accuracy_temp\n",
    "                self.precision = self.precision + precision_temp\n",
    "                self.recall = self.recall+ recall_temp\n",
    "                self.f1= self.f1 + f1_temp\n",
    "\n",
    "                \n",
    "                if details:\n",
    "                    print(\"*\"*25,  \" ITERATION - \", i+1, \"*\"*25)\n",
    "                    print(\"-\"*35)\n",
    "                    print('%50s%s' % (\"Accuracy Score :\", accuracy_temp))\n",
    "                    print('%50s%s' % (\"Precision Score :\", precision_temp))\n",
    "                    print('%50s%s' % (\"Recall Score :\", recall_temp))\n",
    "                    print('%50s%s' % (\"F1 Score :\", f1_temp))\n",
    "                    print('%50s%s' % (\"Hamming Loss :\", hamming_loss))\n",
    "                    if test_X:\n",
    "#                         precision, recall, thresholds = metrics.precision_recall_curve(test_Y, predict)\n",
    "#                         print('%50s%s' % (\"average_precision_score :\", metrics.average_precision_score(test_Y, predict, average=self.average)))\n",
    "#                         print('%50s%s' % (\"fbeta_score :\", metrics.fbeta_score(test_Y, predict)))\n",
    "#                         print('%50s%s' % (\"roc_auc_score :\", metrics.roc_auc_score(test_Y, predict, average=self.average)))\n",
    "                        print(\"-\"*35)\n",
    "                        print(metrics.classification_report(test_Y, predict))\n",
    "                        print(\"-\"*35)\n",
    "                        print(\"Confusion Matrix:\\n\\n\", metrics.confusion_matrix(test_Y, predict))\n",
    "\n",
    "                    else:\n",
    "#                         precision, recall, thresholds = metrics.precision_recall_curve(y_test, predict)\n",
    "                        print('%50s%s' % (\"Average Precision Score :\", metrics.average_precision_score(y_test, predict, average=self.average)))\n",
    "                        print('%50s%s' % (\"Fbeta Score :\", metrics.fbeta_score(y_test, predict)))\n",
    "                        print('%50s%s' % (\"Roc Auc Score :\", metrics.roc_auc_score(y_test, predict, average=self.average)))\n",
    "                        print(\"-\"*35)\n",
    "                        print(metrics.classification_report(y_test, predict))\n",
    "                        print(\"-\"*35)\n",
    "                        print(\"Confusion Matrix:\\n\\n\", metrics.confusion_matrix(y_test, predict))\n",
    "                    print(\"-\"*35)\n",
    "                    print(\"\\n\")\n",
    "\n",
    "                i+=1\n",
    "\n",
    "            split_num = self.splitter.get_n_splits()\n",
    "\n",
    "            self.accuracy = self.accuracy/split_num\n",
    "            self.precision = self.precision/split_num\n",
    "            self.recall = self.recall/split_num\n",
    "            self.f1 = self.f1/split_num\n",
    "\n",
    "            \n",
    "        else:\n",
    "            model.fit(self.train_X, self.train_Y)\n",
    "            predict = model.predict(self.test_X)\n",
    "            \n",
    "            self.accuracy = metrics.accuracy_score(test_Y, predict)\n",
    "            self.precision = metrics.precision_score(test_Y, predict, average=self.average)\n",
    "            self.recall = metrics.recall_score(test_Y, predict, average=self.average)\n",
    "            self.f1 = metrics.f1_score(test_Y, predict, average=self.average)\n",
    "            hamming_loss = metrics.hamming_loss(test_Y, predict)\n",
    "\n",
    "            \n",
    "\n",
    "        if self.report:\n",
    "            if self.splitter:\n",
    "                print(\"*\"*50, \" Average For\", i+1, \" Folds\", \"*\"*50)\n",
    "        \n",
    "            print('%50s%s' % (\"Average Accuracy Score: \", self.accuracy))\n",
    "            print('%50s%s' % (\"Average Precision Score: \", self.precision))\n",
    "            print('%50s%s' % (\"Average Recall Score: \", self.recall))\n",
    "            print('%50s%s' % (\"Average F1 Score: \", self.f1))\n",
    "\n",
    "\n",
    "        return self.accuracy, self.precision, self.recall, self.f1\n",
    "    \n",
    "    def grid(self, target):\n",
    "        print(\"Spliter Description:\")\n",
    "        print(self.splitter)\n",
    "        print(\"targets: \", target, \"\\n\\n\")\n",
    "        \n",
    "        evaluation = {}\n",
    "        \n",
    "        if self.models==None:\n",
    "            models_names_obj = Model(\"Classification\")\n",
    "            self.models = models_names_obj.get_models()\n",
    "            \n",
    "        for model in self.models:\n",
    "            evaluation_temp = []\n",
    "            accuracy, precision, recall, f1 = self.model_evaluation(self.models[model], target)\n",
    "            evaluation_temp.append(accuracy)\n",
    "            evaluation_temp.append(precision)\n",
    "            evaluation_temp.append(recall)\n",
    "            evaluation_temp.append(f1)\n",
    "\n",
    "            evaluation[model] = evaluation_temp\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "        rows_list = []\n",
    "\n",
    "        for name in evaluation:\n",
    "            rows_list.append([name]+evaluation[name])\n",
    "\n",
    "        evaluation_pd = pd.DataFrame(rows_list, columns=['model', 'accuracy', 'precision', 'recall', 'f1']) \n",
    "        \n",
    "        return evaluation_pd\n",
    "    \n",
    "    def multi_target(self):\n",
    "        evaluations_dict = {}\n",
    "        for target in self.targets:\n",
    "            evaluations_dict[target] = self.grid(target)\n",
    "        \n",
    "        return evaluations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelRegression:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, targets, splitter, models, average, report, details):\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y\n",
    "        \n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y\n",
    "        \n",
    "        self.targets = targets\n",
    "\n",
    "        self.splitter = splitter\n",
    "        self.models = models\n",
    "        self.trained_models = None\n",
    "        \n",
    "        self.average = average\n",
    "        self.report = report\n",
    "        self.details = details\n",
    "        \n",
    "        self.explained_variance_score_val = 0\n",
    "        self.mean_absolute_error_val = 0\n",
    "        self.mean_squared_error_val = 0\n",
    "        self.mean_squared_log_error_val = 0\n",
    "        self.median_absolute_error_val = 0\n",
    "        self.r2_score_val = 0\n",
    "    \n",
    "    def reset_score(self):\n",
    "        self.explained_variance_score_val = 0\n",
    "        self.mean_absolute_error_val = 0\n",
    "        self.mean_squared_error_val = 0\n",
    "        self.mean_squared_log_error_val = 0\n",
    "        self.median_absolute_error_val = 0\n",
    "        self.r2_score_val = 0\n",
    "        \n",
    "            \n",
    "    def model_evaluation(self, model, target):\n",
    "        self.reset_score()\n",
    "        if report:\n",
    "            print(\"Model Description:\")\n",
    "            print(model)\n",
    "            print(\"-\"*100,\"\\n\")\n",
    "\n",
    "        if splitter:\n",
    "            i=0\n",
    "            train_Y = np.array(self.train_Y[target], dtype='int64')\n",
    "\n",
    "            \n",
    "            for train_index, test_index in self.splitter.split(self.train_X, train_Y):\n",
    "                X_train, X_test = self.train_X[train_index], self.train_X[test_index]\n",
    "                y_train, y_test = train_Y[train_index], train_Y[test_index]\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                if test_X:\n",
    "                    predict = model.predict(test_X)\n",
    "                    explained_variance_score_temp = metrics.explained_variance_score(test_Y, predict)\n",
    "                    mean_absolute_error_temp = metrics.mean_absolute_error(test_Y, predict)\n",
    "                    mean_squared_error_temp = metrics.mean_squared_error(test_Y, predict)\n",
    "                    mean_squared_log_error_temp = metrics.mean_squared_log_error(test_Y, predict)\n",
    "                    median_absolute_error_temp = metrics.median_absolute_error(test_Y, predict)\n",
    "                    r2_score_temp = metrics.r2_score(test_Y, predict)\n",
    "                else:\n",
    "                    predict = model.predict(X_test)\n",
    "                    explained_variance_score_temp = metrics.explained_variance_score(y_test, predict)\n",
    "                    mean_absolute_error_temp = metrics.mean_absolute_error(y_test, predict)\n",
    "                    mean_squared_error_temp = metrics.mean_squared_error(y_test, predict)\n",
    "                    mean_squared_log_error_temp = metrics.mean_squared_log_error(y_test, predict)\n",
    "                    median_absolute_error_temp = metrics.median_absolute_error(y_test, predict)\n",
    "                    r2_score_temp = metrics.r2_score(y_test, predict)\n",
    "\n",
    "\n",
    "                self.explained_variance_score_val = self.explained_variance_score_val + explained_variance_score_temp\n",
    "                self.mean_absolute_error_val = self.mean_absolute_error_val + mean_absolute_error_temp\n",
    "                self.mean_squared_error_val = self.mean_squared_error_val + mean_squared_error_temp\n",
    "                self.mean_squared_log_error_val = self.mean_squared_log_error_val + mean_squared_log_error_temp\n",
    "                self.median_absolute_error_val = self.median_absolute_error_val + median_absolute_error_temp\n",
    "                self.r2_score_val = self.r2_score_val + r2_score_temp\n",
    "\n",
    "                if details:\n",
    "                    print(\"*\"*25,  \" ITERATION - \", i+1, \"*\"*25)\n",
    "                    print(\"-\"*35)\n",
    "                    print('%50s%s' % (\"explained_variance_score_temp :\", explained_variance_score_temp))\n",
    "                    print('%50s%s' % (\"mean_absolute_error_temp :\", mean_absolute_error_temp))\n",
    "                    print('%50s%s' % (\"mean_squared_error_temp :\", mean_squared_error_temp))\n",
    "                    print('%50s%s' % (\"median_absolute_error_temp :\", median_absolute_error_temp))\n",
    "                    print('%50s%s' % (\"mean_squared_log_error_temp :\", mean_squared_log_error_temp))\n",
    "                    print('%50s%s' % (\"median_absolute_error_temp :\", median_absolute_error_temp))\n",
    "                    print('%50s%s' % (\"r2_score_val :\", r2_score_val))\n",
    "                    print(\"-\"*35)\n",
    "                    print(\"\\n\")\n",
    "                i+=1\n",
    "\n",
    "            split_num = splitter.get_n_splits()\n",
    "\n",
    "            self.explained_variance_score_val = self.explained_variance_score_val/split_num\n",
    "            self.mean_absolute_error_val = self.mean_absolute_error_val/split_num\n",
    "            self.mean_squared_error_val = self.mean_squared_error_val/split_num\n",
    "            self.median_absolute_error_val = self.median_absolute_error_val/split_num\n",
    "            self.r2_score_val = self.r2_score_val/split_num\n",
    "\n",
    "        else:\n",
    "            model.fit(train_X, train_Y)\n",
    "            predict = model.predict(test_X)\n",
    "\n",
    "            self.explained_variance_score = metrics.explained_variance_score(test_Y, predict)\n",
    "            self.mean_absolute_error = metrics.mean_absolute_error(test_Y, predict)\n",
    "            self.mean_squared_error = metrics.mean_squared_error(test_Y, predict)\n",
    "            self.mean_squared_log_error = metrics.mean_squared_log_error(test_Y, predict)\n",
    "            self.median_absolute_error = metrics.median_absolute_error(test_Y, predict)\n",
    "            self.r2_score_temp = metrics.r2_score(test_Y, predict)\n",
    "\n",
    "        if report:\n",
    "            if splitter:\n",
    "                print(\"*\"*40, \" Average For\", i+1, \" Folds\", \"*\"*40)\n",
    "\n",
    "            print('%50s%s' % (\"Average explained_variance_score: \", self.explained_variance_score_val))\n",
    "            print('%50s%s' % (\"Average mean_absolute_error: \", self.mean_absolute_error_val))\n",
    "            print('%50s%s' % (\"Average mean_squared_error: \", self.mean_squared_error_val))\n",
    "            print('%50s%s' % (\"Average mean_squared_log_error: \", self.mean_squared_log_error_val))\n",
    "            print('%50s%s' % (\"Average median_absolute_error: \", self.median_absolute_error_val))\n",
    "            print('%50s%s' % (\"Average r2_score: \", self.r2_score_val))\n",
    "            print(\"\\n\")\n",
    "            print(\"*\"*100)\n",
    "\n",
    "        return model, self.explained_variance_score_val, self.mean_absolute_error_val, self.mean_squared_error_val, self.mean_squared_log_error_val, self.median_absolute_error_val, self.r2_score_val\n",
    "\n",
    "    def grid(self, target):\n",
    "        print(\"Spliter Description:\")\n",
    "        print(self.splitter)\n",
    "        print(\"targets: \", target, \"\\n\\n\")\n",
    "        \n",
    "        trained_models = {}\n",
    "        evaluation = {}\n",
    "        \n",
    "        if self.models==None:\n",
    "            models_names_obj = Model(\"Regression\")\n",
    "            self.models = models_names_obj.get_models()\n",
    "            \n",
    "        for model in self.models:\n",
    "            evaluation_temp = []\n",
    "            model_new, explained_variance_score_val, mean_absolute_error_val, mean_squared_error_val, mean_squared_log_error_val, median_absolute_error_val, r2_score_val = self.model_evaluation(self.models[model], target)\n",
    "            evaluation_temp.append(explained_variance_score_val)\n",
    "            evaluation_temp.append(mean_absolute_error_val)\n",
    "            evaluation_temp.append(mean_squared_error_val)\n",
    "            evaluation_temp.append(mean_squared_log_error_val)\n",
    "            evaluation_temp.append(median_absolute_error_val)            \n",
    "            evaluation_temp.append(r2_score_val)\n",
    "\n",
    "            evaluation[model] = evaluation_temp\n",
    "            trained_models[model] = model_new\n",
    "            \n",
    "            \n",
    "\n",
    "#             gc.collect()\n",
    "\n",
    "        rows_list = []\n",
    "\n",
    "        for name in evaluation:\n",
    "            \n",
    "            rows_list.append([name]+evaluation[name])\n",
    "\n",
    "        evaluation_pd = pd.DataFrame(rows_list, columns=['model', 'explained_variance_score', 'mean_absolute_error', 'mean_squared_error', 'mean_squared_log_error', 'median_absolute_error', 'r2_score']) \n",
    "\n",
    "        return trained_models, evaluation_pd\n",
    "    \n",
    "    def multi_target(self):\n",
    "        trained_models_multi_target = {}\n",
    "        evaluations_dict = {}\n",
    "        for target in self.targets:\n",
    "            trained_models, evaluations_dict[target] = self.grid(target)\n",
    "            trained_models_multi_target[target] = trained_models\n",
    "        \n",
    "        return trained_models_multi_target, evaluations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliter Description:\n",
      "KFold(n_splits=5, random_state=True, shuffle=True)\n",
      "targets:  SalePrice \n",
      "\n",
      "\n",
      "Model Description:\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "         n_estimators=50, random_state=None)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.6\n",
      "                     Average mean_absolute_error: 0.0027397260273972603\n",
      "                      Average mean_squared_error: 0.0027397260273972603\n",
      "                  Average mean_squared_log_error: 0.006581548135865772\n",
      "                   Average median_absolute_error: 0.0\n",
      "                                Average r2_score: 0.5993127147766323\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "BaggingRegressor(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.4\n",
      "                     Average mean_absolute_error: 0.002671232876712329\n",
      "                      Average mean_squared_error: 0.002061643835616438\n",
      "                  Average mean_squared_log_error: 0.005453763132692961\n",
      "                   Average median_absolute_error: 0.0\n",
      "                                Average r2_score: 0.3993127147766323\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.4\n",
      "                     Average mean_absolute_error: 0.003424657534246575\n",
      "                      Average mean_squared_error: 0.003424657534246575\n",
      "                  Average mean_squared_log_error: 0.008226935169832215\n",
      "                   Average median_absolute_error: 0.0\n",
      "                                Average r2_score: 0.3993127147766323\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.2\n",
      "                     Average mean_absolute_error: 0.0021232876712328768\n",
      "                      Average mean_squared_error: 0.001226027397260274\n",
      "                  Average mean_squared_log_error: 0.0035476194406933153\n",
      "                   Average median_absolute_error: 0.0\n",
      "                                Average r2_score: 0.19931271477663232\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "          min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.4\n",
      "                     Average mean_absolute_error: 0.002054794520547945\n",
      "                      Average mean_squared_error: 0.002054794520547945\n",
      "                  Average mean_squared_log_error: 0.004936161101899329\n",
      "                   Average median_absolute_error: 0.0\n",
      "                                Average r2_score: 0.3993127147766323\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=False,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=None)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.0\n",
      "                     Average mean_absolute_error: 0.0006849315071792479\n",
      "                      Average mean_squared_error: 0.0006849315068493151\n",
      "                  Average mean_squared_log_error: 0.001645387033966443\n",
      "                   Average median_absolute_error: 6.139613970434591e-34\n",
      "                                Average r2_score: -0.0006872852233676952\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.4\n",
      "                     Average mean_absolute_error: 0.0029111656006932337\n",
      "                      Average mean_squared_error: 0.00274634265996774\n",
      "                  Average mean_squared_log_error: 0.006703024434691503\n",
      "                   Average median_absolute_error: 7.380317578291699e-06\n",
      "                                Average r2_score: -0.0006872852233676952\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
      "        tol=1e-05, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.0\n",
      "                     Average mean_absolute_error: 0.001376266413769971\n",
      "                      Average mean_squared_error: 0.0007055381825605668\n",
      "                  Average mean_squared_log_error: 0.0017440337812796296\n",
      "                   Average median_absolute_error: 0.00011795146243026302\n",
      "                                Average r2_score: -0.0006872852233676952\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.0\n",
      "                     Average mean_absolute_error: 0.006839363984317813\n",
      "                      Average mean_squared_error: 0.000812931438712932\n",
      "                  Average mean_squared_log_error: 0.0022608529641761966\n",
      "                   Average median_absolute_error: 0.004346838048486079\n",
      "                                Average r2_score: -0.0006872852233676952\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "     random_state=None, tol=0.0001, verbose=0)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.0\n",
      "                     Average mean_absolute_error: 0.002974606273802466\n",
      "                      Average mean_squared_error: 0.000695882289314214\n",
      "                  Average mean_squared_log_error: 0.0017002023501164337\n",
      "                   Average median_absolute_error: 0.0020140222472180267\n",
      "                                Average r2_score: -0.0006872852233676952\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: -0.7377462664849155\n",
      "                     Average mean_absolute_error: 0.08298082450313524\n",
      "                      Average mean_squared_error: 0.013821598614479087\n",
      "                  Average mean_squared_log_error: 0.07751570160489815\n",
      "                   Average median_absolute_error: 0.06101551661721512\n",
      "                                Average r2_score: -0.823294874449989\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "NuSVR(C=1.0, cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
      "   max_iter=-1, nu=0.5, shrinking=True, tol=0.001, verbose=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.0\n",
      "                     Average mean_absolute_error: 0.0017656418390151131\n",
      "                      Average mean_squared_error: 0.0007382320499410191\n",
      "                  Average mean_squared_log_error: 0.001873726370842341\n",
      "                   Average median_absolute_error: 0.00038216205427063716\n",
      "                                Average r2_score: -0.0006872852233676952\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,\n",
      "              fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, random_state=None, shuffle=True,\n",
      "              tol=None, verbose=0, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.0\n",
      "                     Average mean_absolute_error: 0.03490247812846929\n",
      "                      Average mean_squared_error: 0.002930305749816641\n",
      "                  Average mean_squared_log_error: 0.013189457621096542\n",
      "                   Average median_absolute_error: 0.02983237277916485\n",
      "                                Average r2_score: -0.0006872852233676952\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.4\n",
      "                     Average mean_absolute_error: 0.0021232876712328763\n",
      "                      Average mean_squared_error: 0.0015410958904109589\n",
      "                  Average mean_squared_log_error: 0.004236531944601356\n",
      "                   Average median_absolute_error: 0.0\n",
      "                                Average r2_score: 0.3993127147766323\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************  Average For 6  Folds ****************************************\n",
      "                Average explained_variance_score: 0.0\n",
      "                     Average mean_absolute_error: 0.04520940989695919\n",
      "                      Average mean_squared_error: 0.003680670903009306\n",
      "                  Average mean_squared_log_error: 0.015530134693442024\n",
      "                   Average median_absolute_error: 0.04627896697665952\n",
      "                                Average r2_score: -0.0006872852233676952\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Model Description:\n",
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False)\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X_file = r'house-prices-advanced-regression-techniques/train.csv'\n",
    "test_X_file = r'house-prices-advanced-regression-techniques/test.csv'\n",
    "\n",
    "file_obj = File(train_X_file, None, test_X_file, None)\n",
    "\n",
    "\n",
    "train_X, train_Y, test_X, test_Y = file_obj.get_content()\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "targets = ['SalePrice']\n",
    "\n",
    "\n",
    "data_obj = Data(train_X, None, test_X, None, False, True, False, targets)\n",
    "\n",
    "\n",
    "train_X, train_Y, test_X, test_Y = data_obj.get_data()\n",
    "\n",
    "###\n",
    "\n",
    "ignore_cols = ['BsmtExposure']\n",
    "val1 = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0}\n",
    "val2 = {'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1, 'NA':0}\n",
    "\n",
    "rating_score = {'ExterQual':val1, 'ExterCond':val1, 'BsmtQual':val1, 'BsmtCond':val1, 'HeatingQC':val1, 'KitchenQual':val1, 'FireplaceQu':val1, 'GarageQual':val1, 'GarageCond':val1, 'PoolQC':val1, 'BsmtFinType1':val2, 'BsmtFinType2':val2}\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "prep_num = PreprocessNumeric()\n",
    "\n",
    "train_X, test_X = prep_num.drop_cols(train_X, test_X, ignore_cols)\n",
    "\n",
    "train_X = prep_num.encoding_type(train_X, rating_score)\n",
    "\n",
    "\n",
    "\n",
    "test_X = prep_num.encoding_type(test_X, rating_score)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "# print(train_X) \n",
    "train_X, train_Y, test_X, test_Y = prep_num.fill_col(train_X, train_Y, None, None)\n",
    "\n",
    "train_Y, test_Y, normalizer_train, normalizer_test = prep_num.normalize_target(train_Y, None)\n",
    "\n",
    "\n",
    "# train_Y[targets[0]] = train_Y_temp\n",
    "#\n",
    "train_X = train_X.values\n",
    "\n",
    "norm = train_Y.max()[0].flatten()[0]\n",
    "\n",
    "train_Y = train_Y/norm\n",
    "\n",
    "# train_Y[targets[0]] = train_Y[targets[0]]/norm\n",
    "\n",
    "\n",
    "# train_Y = train_Y.values\n",
    "\n",
    "# if test_X:\n",
    "#     test_X = test_X.values\n",
    "# if test_Y:\n",
    "#     test_Y = test_Y.values\n",
    "\n",
    "# train_Y, test_Y, normalizer_train, normalizer_test = prep_num.normalize(None, train_Y, None, test_Y)\n",
    "\n",
    "\n",
    "# splitter_name = \"StratifiedShuffleSplit\"\n",
    "splitter_name = \"KFold\"\n",
    "n_splits = 5\n",
    "test_size = 0.25\n",
    "random_state = True\n",
    "\n",
    "splitter_obj = Splitter(splitter_name, n_splits, test_size, random_state)\n",
    "splitter = splitter_obj.get_splitter()\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "models = None\n",
    "\n",
    "average = \"weighted\"\n",
    "report = 1\n",
    "details = 0\n",
    "\n",
    "m = ModelRegression(train_X, train_Y, None, None, targets, splitter, models, average, report, details)\n",
    "\n",
    "trained_models, evaluation_pd = m.grid(targets[0])\n",
    "\n",
    "evaluation = evaluation_pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation = evaluation_pd\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import figure\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "labels= ['explained_variance_score', 'mean_absolute_error', 'mean_squared_error', 'mean_squared_log_error', 'median_absolute_error', 'r2_score']\n",
    "\n",
    "x = np.array(evaluation_pd['model'])\n",
    "evaluation = evaluation[labels]\n",
    "\n",
    "\n",
    "# os.mkdir(\"output\")\n",
    "# os.mkdir(\"output/plots\")\n",
    "\n",
    "for n in range(len(labels)):\n",
    "    fig = plt.figure(num=None, figsize=(14, 6), dpi=250)\n",
    "    \n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    y = evaluation[labels[n]]\n",
    "\n",
    "    plt.plot(x, y, label = labels[n])\n",
    "\n",
    "    leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=True, fancybox=True)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    plt.legend()\n",
    "#     plt.xlabel('Model', fontsize=15)\n",
    "    plt.ylabel('Score', fontsize=15)   \n",
    "    plt.xticks(rotation=90)\n",
    "    ax.tick_params(labelsize='large', width=5)\n",
    "    ax.grid(True, linestyle='-.')\n",
    "    plt.tight_layout()\n",
    "    plt.title(re.sub('[^a-zA-Z0-9]', ' ', labels[n]).title(), fontsize=20)\n",
    "    plt.show()\n",
    "    fig.savefig(\"output/plots/\"+labels[n])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "labels= ['accuracy', 'precision', 'recall', 'f1']\n",
    "x = np.array(evaluation['model'])\n",
    "\n",
    "for item in evaluation_pd:\n",
    "    evaluation = evaluation_pd[item]\n",
    "    \n",
    "    figure(num=None, figsize=(14, 6), dpi=250)\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    for n in range(len(labels)):\n",
    "        y = evaluation[labels[n]]\n",
    "        \n",
    "        plt.plot(x, y, label = labels[n])\n",
    "\n",
    "    plt.title(item)\n",
    "    leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=True, fancybox=True)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Score')   \n",
    "    plt.xticks(rotation=90)\n",
    "    ax.tick_params(labelsize='large', width=5)\n",
    "    ax.grid(True, linestyle='-.')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
